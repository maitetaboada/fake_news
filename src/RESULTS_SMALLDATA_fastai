Loading data snopes...
(118, 5)
0    mixture
1     mfalse
2    mixture
3    mixture
4      mtrue
5     ffalse
6     mfalse
7      mtrue
8     ffalse
9     ffalse
Name: label, dtype: object
['mixture' 'mfalse' 'mtrue' 'ffalse' 'ftrue']
Data from Snopes looks like...
0     Massive Pedophile Ring With '70,000 Elite Mem...
1     NBC Bay Area's SkyRanger on Saturday captured...
2     Today is Flag Day, the anniversary of when 19...
3     HONOLULU Federal authorities on Friday added ...
4     Text smaller    Text bigger    We have all he...
5     A 79-year-old retired officer of the CIA, Bil...
6     Governor Jerry Brown is retiring but not befo...
7     Sneed: 108 could be the Cubs magic number thi...
8     Clint Eastwood, more famous for westerns than...
9     Delaware City Council passed a resolution thi...
Name: data, dtype: object
[5, 1, 5, 5, 0, 1, 1, 0, 1, 1]
0    48
1    44
5    26
dtype: int64
Loading data buzzfeedtop...
(33, 15)
                                               title        ...              author_phase2
0  Babysitter transported to hospital after inser...        ...          Barbara Jennnings
1  FBI seizes over 3,000 penises during raid at m...        ...          Barbara Jennnings
2  Charles Manson to be released on parole, to Jo...        ...                        NaN

[3 rows x 15 columns]
Data from BuzzFeed looks like...
0    Cincinnati, Ohio | A 31-year old woman was adm...
1    FBI agents made an astonishing discovery this ...
2    Giant Squid Washes Ashore on Lake Michigan Mic...
3    Police have reportedly launched a murder inves...
4    Beaumont, Texas | An employee of the Jefferson...
5    WASHINGTON, DC (By J. McConkey)A group of lead...
6    WASHINGTON, D.C.  In another sweeping move aim...
7    Columbus, Ohio | An 83-year old woman was arre...
8    A couple was transported to the hospital in a ...
9    Darrel Whitaker from Glenwood Springs in Color...
Name: original_article_text_phase2, dtype: object
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
1    33
dtype: int64
Loading data perez...
(500, 3)
   Unnamed: 0                                               text  label
0           0  Jennifer Aniston dashes 'Friends' reunion hope...  legit
1           1  This Is What Brad Pitt Has Been Texting Jennif...  legit
2           2  Jennifer Aniston's spokesman denies reports th...  legit
Data from perez looks like...
0    Jennifer Aniston dashes 'Friends' reunion hope...
1    This Is What Brad Pitt Has Been Texting Jennif...
2    Jennifer Aniston's spokesman denies reports th...
3    Jennifer Aniston sparks adoption rumors\n\nBef...
4    Jennifer Aniston denies she had an affair with...
5    Jennifer Aniston: I'm Not a 'Sad, Childless Hu...
6    Jennifer Aniston Finally Pregnant At 48 Years ...
7    Brad Pitt is not reuniting with Jennifer Anist...
8    Miley And Liam Fighting? False Rumors Swirl Th...
9    Kristen Stewart not dropping another "Twilight...
Name: text, dtype: object
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
1    250
0    250
dtype: int64
Data loaded from disk!
(646,) 215
Cross validation starts:
[108 109 110 111 ... 642 643 644 645] [  0   1   2   3 ... 427 428 429 430]
(430,)
(216,)


 A sample of classifier training data:
   label                                               text
0      0   As you well know, bullets are designed to kil...
1      0   Washington, D.C., Sept. 26, 2001 More than tw...
2      0  White Female Cop Shoots and Kills Black Suspec...
3      0   On Media Blog Archives Select Date December, ...
4      0   11:20 a.m.: This post has been updated to inc...
5      0   Today, the U.S. Department of Health and Huma...
6      0   Published: 09:34 BST, 31 July 2017 | Updated:...
7      0   Point Nemo (or, One Thousand and Four Hundred...
8      0  Rudy Giuliani said Donald Trump should be hims...
9      0   In the era of primal Trump, West Wing adviser...
10     0   Its called Gray Death and it lays waste every...
11     0   Sushi lovers beware!  A California man who at...
12     0   Mr. Bernstein said the presidents language ma...
13     0  Barack Obama is planning on leaving office the...
14     0   Mark your calendars: a series of three superm...
15     0   Animal rights activists are revolted by a ser...
16     0   In seven years, the casualties of Syrias civi...
17     0   Updated: Thursday November 26, 2015 : 10:43 E...
18     0   The right has claimed the mantle of family va...
19     0   1.5k SHARES SHARE THIS STORY  President Donal...
20     0   Molecular genetic tools have been used to dis...
21     0   Does Your Dog Feel Jealous, Or Is That A Pure...
22     0   This page was last updated on 20 January 2016...
23     0   President Obama found his private moment of p...
24     0   Some critics see her change as political oppo...
25     0   Theyve pretty much emasculated enforcement, w...
26     0   Breaking News Emails Get breaking news alerts...
27     0   An all-out trade war looms as Donald Trump an...
28     0   Array ( =&gt; 2016-02-02 [displayText] =&gt; ...
29     0   Arizona state Rep. Eric Descheenie, photo by ...
..   ...                                                ...
70     0   "It's the next thing that's inevitably going ...
71     0   A Seattle woman who was flying to San Francis...
72     0   Georgia Congressman Drew Ferguson was lambast...
73     0   Image: Lketieteen ja biotieteiden tiedekunta ...
74     0  Donald Trump pushed back against Hillary Clint...
75     0  Trump 'happy' he didn't bring up Bill Clinton'...
76     0   Digitizing sponsor U.S. War Department  Admon...
77     0   Is it a strawberry that looks like a pineappl...
78     0   Robert Bork's Supreme Court Nomination 'Chang...
79     0   WASHINGTON President Trump slapped steep tari...
80     0   The president-elect's home in New York was la...
81     0  ?[Ahmad Khan Rahami] should go to jail and bes...
82     0   The 2016 Election has been a roller coaster o...
83     0   In this May 11, 2015, file photo, Dallas Mave...
84     0  Controversial Leader Calls For Illegal Immigra...
85     0  VIDEO: Dramatic moment Palestinian lures Israe...
86     0   When California lawmakers return to the Capit...
87     0   Breaking News Emails Get breaking news alerts...
88     0   Introduction  Fetal cell microchimerism is de...
89     0   President Trump grew frustrated with lawmaker...
90     0   A school shooting at Marjory Stoneman Douglas...
91     0  The Department of Homeland Security's inspecto...
92     0   The Twelfth Amendment cannot be understood ou...
93     0   TAMRON HALL : Let's talk about your speech. I...
94     0   The Demon-Haunted World  Carl Sagan  Random H...
95     0   Buy Photo Duke Energy charged a Covington bus...
96     0   A damaged house is visible among stripped tre...
97     0  ?The Democrats are insisting upon Flint, and w...
98     0   Donald Trump makes a lot of polarizing statem...
99     0   Oh, were you expecting a Weiner story?  No, f...

[100 rows x 2 columns]
Language model loaded!
Building the text classifier...
epoch  train_loss  valid_loss  accuracy
1      0.703991    0.678931    0.597222
epoch  train_loss  valid_loss  accuracy
1      0.641432    0.678583    0.611111
epoch  train_loss  valid_loss  accuracy
1      0.635393    0.694030    0.555556
epoch  train_loss  valid_loss  accuracy
1      0.629359    0.698868    0.587963
2      0.611180    0.688923    0.620370
3      0.600194    0.724185    0.597222
4      0.597256    0.697061    0.601852
5      0.572586    0.693691    0.601852
6      0.567421    0.743526    0.578704
7      0.569215    0.717669    0.601852
8      0.549758    0.744754    0.569444
9      0.543349    0.789063    0.587963
10     0.521579    0.785942    0.578704
11     0.513561    0.785007    0.592593
12     0.494057    0.772745    0.583333
13     0.477010    0.828195    0.592593
14     0.476310    0.820473    0.587963
15     0.447888    0.827140    0.583333
saving the classifier...
Prediction for sentence " Hilary Clinton won the 2016 US election" is ('0', tensor(0), tensor([0.9271, 0.0729]))
Results on all  data:
              precision    recall  f1-score   support

           0       0.79      0.84      0.82       323
           1       0.83      0.78      0.80       323

   micro avg       0.81      0.81      0.81       646
   macro avg       0.81      0.81      0.81       646
weighted avg       0.81      0.81      0.81       646

Results on validation data:
              precision    recall  f1-score   support

           0       0.59      0.60      0.60       108
           1       0.59      0.58      0.59       108

   micro avg       0.59      0.59      0.59       216
   macro avg       0.59      0.59      0.59       216
weighted avg       0.59      0.59      0.59       216

Test results on data sampled only from snopes (snopes312 dataset manually checked right items -- unseen claims):
[[ 0 48]
 [ 1 44]
 [ 5 26]]
Discarding items for label 5
Final size of dataset:
[[ 0 48]
 [ 1 44]]
Final size of remaining dataset:
[[ 5 26]]
              precision    recall  f1-score   support

           0       0.67      0.69      0.68        48
           1       0.65      0.64      0.64        44

   micro avg       0.66      0.66      0.66        92
   macro avg       0.66      0.66      0.66        92
weighted avg       0.66      0.66      0.66        92

Test results on data sampled only from buzzfeedTop (mixed claims):
[[ 1 33]]
Final size of dataset:
[[ 1 33]]
Final size of remaining dataset:
[]
/home/ftorabia/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.82      0.90        33

   micro avg       0.82      0.82      0.82        33
   macro avg       0.50      0.41      0.45        33
weighted avg       1.00      0.82      0.90        33

Test results on data sampled only from perez (celebrity stories):
[[  0 250]
 [  1 250]]
Final size of dataset:
[[  0 250]
 [  1 250]]
Final size of remaining dataset:
[]
              precision    recall  f1-score   support

           0       0.58      0.84      0.69       250
           1       0.71      0.38      0.49       250

   micro avg       0.61      0.61      0.61       500
   macro avg       0.64      0.61      0.59       500
weighted avg       0.64      0.61      0.59       500

[  0   1   2   3 ... 642 643 644 645] [108 109 110 111 ... 535 536 537 538]
(430,)
(216,)


 A sample of classifier training data:
   label                                               text
0      0  Clinton gets it wrong on 'small business' job ...
1      0   Uber launched a fleet of its much anticipated...
2      0  Story highlights US State Department commends ...
3      0   The motive for the Florida school shooting re...
4      0   For the past several months, DreamHost has be...
5      0   Skip all  Welcome home! This timeline is wher...
6      0   Cattle farmers struggling with record corn pr...
7      0   Knox Machinery  New &amp; Used CNC Machines, ...
8      0  Sanders planning a ?very, very vigorous? Clint...
9      0   Marine Helicopter Squadron One (HMX-1) was es...
10     0   The deadline arrived without a deal. The U.S....
11     0   Donald Trump, current GOP front-runner and gu...
12     0   ASHA JAQUILLA DEGREE  Case Type :Endangered M...
13     0   The Guggenheim is gearing up for a special ex...
14     0   The Dunblane school massacre took place at Du...
15     0   Update: On March 30, 2017, the N.C. General A...
16     0  Bill Clinton's speech will be a ?personal refl...
17     0  Story highlights Monday night marks the first ...
18     0   Gabriel Bouys/AFP/Getty Images  At age 91, in...
19     0   HOLLYWOOD (CBSLA.com) Authorities say someone...
20     0  The LA Times/USC Daily Tracking Poll began rep...
21     0   Story highlights A father and son put a bison...
22     0   Portable, Practical Educational Preparation o...
23     0   Heard about the guy who found the dead mouse ...
24     0   Washington, D.C. U.S. Sen. Jeff Flake (R-Ariz...
25     0   The brides parents Christopher and Denice, al...
26     0   POSTED: 4:43 pm CST December 11, 2003  A holi...
27     0   Photo: Sean Rayford/Getty Images  North Carol...
28     0   Animal health officials said there are two di...
29     0   The dust particles that create Perseid meteor...
..   ...                                                ...
70     0   Here's my review on one of the three books th...
71     0  Milwaukee Sheriff David A. Clarke Jr. has been...
72     0   No one accused Donald Trump of being a racist...
73     0  Story highlights There are an estimated 200,00...
74     0   It's been six weeks since Maria left Puerto R...
75     0   Introduction to the ADA  The Americans with D...
76     0   The IRS has decided to drop existing audits i...
77     0   Please enable Javascript to watch this video ...
78     0   Please enable Javascript to watch this video ...
79     0   If you add China and fireworks together, you ...
80     0   The makers described demand for the idea as "...
81     0  A Treasury Department spokesman acknowledged o...
82     0  Story highlights Bush will deliver his first l...
83     0   Ventura, California The thousands of men and ...
84     0   This website uses profiling cookies, includin...
85     0   U.S. Virgin Islands Gov. Kenneth Mapp signed ...
86     0   Facility Main Telephone Line: 254-2500  Field...
87     0   Breaking News Emails Get breaking news alerts...
88     0   has never been considered controversial. The ...
89     0   LEAVE TOWER OF TERROR ALONE pic.twitter.com/5...
90     0  Bernie Sanders has been a mayor, a congressman...
91     0   The Crawford County Sheriff says one of his i...
92     0   We had a pretty eventful Saturday.  On the wa...
93     0   Summer Hours 2018-06-25 2:40:17 PM Provincial...
94     0   This is historical material, "frozen in time....
95     0   Chelsea Clinton has in-laws now. You wouldnt ...
96     0   A monster alligator went on an amble though B...
97     0   [ 7-26-2016 ] The U.S. Food and Drug Administ...
98     0   HOME | Arts &amp; Entertainment  Miro Paintin...
99     0  A Dallas police officer, seeing red after seve...

[100 rows x 2 columns]
Language model loaded!
Building the text classifier...
epoch  train_loss  valid_loss  accuracy
1      0.731995    0.693560    0.537037
epoch  train_loss  valid_loss  accuracy
1      0.651941    0.699671    0.546296
epoch  train_loss  valid_loss  accuracy
1      0.625424    0.717097    0.564815
epoch  train_loss  valid_loss  accuracy
1      0.611259    0.683686    0.569444
2      0.629699    0.686975    0.587963
3      0.602809    0.748642    0.564815
4      0.578966    0.736752    0.560185
5      0.563087    0.866725    0.583333
6      0.561958    0.940678    0.550926
7      0.562773    0.898717    0.546296
8      0.544664    0.774695    0.583333
9      0.513852    0.786703    0.606481
10     0.505686    0.889354    0.569444
11     0.504512    0.879151    0.597222
12     0.500564    0.958784    0.550926
13     0.500544    0.905111    0.597222
14     0.493521    0.883285    0.597222
15     0.505170    0.895791    0.550926
saving the classifier...
Prediction for sentence " Hilary Clinton won the 2016 US election" is ('0', tensor(0), tensor([0.9020, 0.0980]))
Results on all  data:
              precision    recall  f1-score   support

           0       0.64      0.93      0.76       323
           1       0.87      0.49      0.62       323

   micro avg       0.71      0.71      0.71       646
   macro avg       0.76      0.71      0.69       646
weighted avg       0.76      0.71      0.69       646

Results on validation data:
              precision    recall  f1-score   support

           0       0.54      0.81      0.65       108
           1       0.62      0.31      0.41       108

   micro avg       0.56      0.56      0.56       216
   macro avg       0.58      0.56      0.53       216
weighted avg       0.58      0.56      0.53       216

Test results on data sampled only from snopes (snopes312 dataset manually checked right items -- unseen claims):
[[ 0 48]
 [ 1 44]
 [ 5 26]]
Discarding items for label 5
Final size of dataset:
[[ 0 48]
 [ 1 44]]
Final size of remaining dataset:
[[ 5 26]]
              precision    recall  f1-score   support

           0       0.56      0.85      0.68        48
           1       0.63      0.27      0.38        44

   micro avg       0.58      0.58      0.58        92
   macro avg       0.60      0.56      0.53        92
weighted avg       0.60      0.58      0.54        92

Test results on data sampled only from buzzfeedTop (mixed claims):
[[ 1 33]]
Final size of dataset:
[[ 1 33]]
Final size of remaining dataset:
[]
/home/ftorabia/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.61      0.75        33

   micro avg       0.61      0.61      0.61        33
   macro avg       0.50      0.30      0.38        33
weighted avg       1.00      0.61      0.75        33

Test results on data sampled only from perez (celebrity stories):
[[  0 250]
 [  1 250]]
Final size of dataset:
[[  0 250]
 [  1 250]]
Final size of remaining dataset:
[]
              precision    recall  f1-score   support

           0       0.52      0.95      0.67       250
           1       0.69      0.11      0.19       250

   micro avg       0.53      0.53      0.53       500
   macro avg       0.60      0.53      0.43       500
weighted avg       0.60      0.53      0.43       500

[  0   1   2   3 ... 535 536 537 538] [216 217 218 219 ... 642 643 644 645]
(432,)
(214,)


 A sample of classifier training data:
   label                                               text
0      0  Clinton gets it wrong on 'small business' job ...
1      0   Uber launched a fleet of its much anticipated...
2      0  Story highlights US State Department commends ...
3      0   The motive for the Florida school shooting re...
4      0   For the past several months, DreamHost has be...
5      0   Skip all  Welcome home! This timeline is wher...
6      0   Cattle farmers struggling with record corn pr...
7      0   Knox Machinery  New &amp; Used CNC Machines, ...
8      0  Sanders planning a ?very, very vigorous? Clint...
9      0   Marine Helicopter Squadron One (HMX-1) was es...
10     0   The deadline arrived without a deal. The U.S....
11     0   Donald Trump, current GOP front-runner and gu...
12     0   ASHA JAQUILLA DEGREE  Case Type :Endangered M...
13     0   The Guggenheim is gearing up for a special ex...
14     0   The Dunblane school massacre took place at Du...
15     0   Update: On March 30, 2017, the N.C. General A...
16     0  Bill Clinton's speech will be a ?personal refl...
17     0  Story highlights Monday night marks the first ...
18     0   Gabriel Bouys/AFP/Getty Images  At age 91, in...
19     0   HOLLYWOOD (CBSLA.com) Authorities say someone...
20     0  The LA Times/USC Daily Tracking Poll began rep...
21     0   Story highlights A father and son put a bison...
22     0   Portable, Practical Educational Preparation o...
23     0   Heard about the guy who found the dead mouse ...
24     0   Washington, D.C. U.S. Sen. Jeff Flake (R-Ariz...
25     0   The brides parents Christopher and Denice, al...
26     0   POSTED: 4:43 pm CST December 11, 2003  A holi...
27     0   Photo: Sean Rayford/Getty Images  North Carol...
28     0   Animal health officials said there are two di...
29     0   The dust particles that create Perseid meteor...
..   ...                                                ...
70     0   Here's my review on one of the three books th...
71     0  Milwaukee Sheriff David A. Clarke Jr. has been...
72     0   No one accused Donald Trump of being a racist...
73     0  Story highlights There are an estimated 200,00...
74     0   It's been six weeks since Maria left Puerto R...
75     0   Introduction to the ADA  The Americans with D...
76     0   The IRS has decided to drop existing audits i...
77     0   Please enable Javascript to watch this video ...
78     0   Please enable Javascript to watch this video ...
79     0   If you add China and fireworks together, you ...
80     0   The makers described demand for the idea as "...
81     0  A Treasury Department spokesman acknowledged o...
82     0  Story highlights Bush will deliver his first l...
83     0   Ventura, California The thousands of men and ...
84     0   This website uses profiling cookies, includin...
85     0   U.S. Virgin Islands Gov. Kenneth Mapp signed ...
86     0   Facility Main Telephone Line: 254-2500  Field...
87     0   Breaking News Emails Get breaking news alerts...
88     0   has never been considered controversial. The ...
89     0   LEAVE TOWER OF TERROR ALONE pic.twitter.com/5...
90     0  Bernie Sanders has been a mayor, a congressman...
91     0   The Crawford County Sheriff says one of his i...
92     0   We had a pretty eventful Saturday.  On the wa...
93     0   Summer Hours 2018-06-25 2:40:17 PM Provincial...
94     0   This is historical material, "frozen in time....
95     0   Chelsea Clinton has in-laws now. You wouldnt ...
96     0   A monster alligator went on an amble though B...
97     0   [ 7-26-2016 ] The U.S. Food and Drug Administ...
98     0   HOME | Arts &amp; Entertainment  Miro Paintin...
99     0  A Dallas police officer, seeing red after seve...

[100 rows x 2 columns]
Language model loaded!
Building the text classifier...
epoch  train_loss  valid_loss  accuracy
1      0.708014    0.691815    0.476636
epoch  train_loss  valid_loss  accuracy
1      0.652530    0.674518    0.621495
epoch  train_loss  valid_loss  accuracy
1      0.632332    0.708055    0.579439
epoch  train_loss  valid_loss  accuracy
1      0.591222    0.753449    0.612150
2      0.566767    0.758841    0.602804
3      0.541066    0.746899    0.663551
4      0.524159    0.743540    0.626168
5      0.502718    0.840668    0.593458
6      0.488400    0.920893    0.621495
7      0.467503    0.950287    0.644860
8      0.457217    0.863372    0.616822
9      0.447452    0.903780    0.626168
10     0.430265    0.876561    0.640187
11     0.404703    0.976475    0.630841
12     0.394879    1.007144    0.607477
13     0.390038    0.919862    0.621495
14     0.384926    1.010890    0.616822
15     0.378325    0.965659    0.602804
saving the classifier...
Prediction for sentence " Hilary Clinton won the 2016 US election" is ('0', tensor(0), tensor([0.7573, 0.2427]))
Results on all  data:
              precision    recall  f1-score   support

           0       0.82      0.88      0.84       323
           1       0.87      0.80      0.83       323

   micro avg       0.84      0.84      0.84       646
   macro avg       0.84      0.84      0.84       646
weighted avg       0.84      0.84      0.84       646

Results on validation data:
              precision    recall  f1-score   support

           0       0.60      0.71      0.65       107
           1       0.64      0.52      0.58       107

   micro avg       0.62      0.62      0.62       214
   macro avg       0.62      0.62      0.61       214
weighted avg       0.62      0.62      0.61       214

Test results on data sampled only from snopes (snopes312 dataset manually checked right items -- unseen claims):
[[ 0 48]
 [ 1 44]
 [ 5 26]]
Discarding items for label 5
Final size of dataset:
[[ 0 48]
 [ 1 44]]
Final size of remaining dataset:
[[ 5 26]]
              precision    recall  f1-score   support

           0       0.60      0.60      0.60        48
           1       0.57      0.57      0.57        44

   micro avg       0.59      0.59      0.59        92
   macro avg       0.59      0.59      0.59        92
weighted avg       0.59      0.59      0.59        92

Test results on data sampled only from buzzfeedTop (mixed claims):
[[ 1 33]]
Final size of dataset:
[[ 1 33]]
Final size of remaining dataset:
[]
/home/ftorabia/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.85      0.92        33

   micro avg       0.85      0.85      0.85        33
   macro avg       0.50      0.42      0.46        33
weighted avg       1.00      0.85      0.92        33

Test results on data sampled only from perez (celebrity stories):
[[  0 250]
 [  1 250]]
Final size of dataset:
[[  0 250]
 [  1 250]]
Final size of remaining dataset:
[]
              precision    recall  f1-score   support

           0       0.62      0.55      0.58       250
           1       0.60      0.67      0.63       250

   micro avg       0.61      0.61      0.61       500
   macro avg       0.61      0.61      0.61       500
weighted avg       0.61      0.61      0.61       500

(py36) ftorabia@Ling-DiscourseLab-GPU1:~/workspace/shared/sfu/fake_news/src$






#######################################################






from fastai import *
from fastai.text import *
#from textutils import DataLoading
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import StratifiedKFold

import random
import numpy as np
import torch

#reprudicibility:
torch.manual_seed(0)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
np.random.seed(0)
random.seed(0)


LOAD_LM_FROM_DISK = True

def load_data_rashkin(file_name, classes = 4):
    print("Loading data...")
    data_train = pd.read_table(file_name, sep='\t', header=None, names=["label", "data"], usecols=[0, 1],
                               dtype={"label": np.str, "data": np.str})
    print(data_train.shape)
    print(data_train[0:6])
    texts = []
    labels = []
    # for i in range(data_train.data.shape[0]):
    #   print(i, type(data_train.data[i]))

    texts = data_train.data
    labels = data_train.label
    '''
    for idx in range(data_train.data.shape[0]):
        text = BeautifulSoup(data_train.data[idx])
        texts.append(clean_str(text.get_text().encode('ascii', 'ignore')))
        labels.append(str(data_train.label[idx]))
    '''
    if( classes == 2):
        transdict = {
            '1': 1,  # Satire
            '2': 1,  # Hoax
            '3': 1,  # Propaganda
            '4': 0  # Truested
        }
    else:
        transdict = {
            '1': 2,  # Satire
            '2': 3,  # Hoax
            '3': 1,  # Propaganda
            '4': 0  # Truested
        }
    labels = [transdict[i] for i in labels]
    #labels = to_cat(np.asarray(labels))
    print(texts[0:6])
    print(labels[0:6])
    return texts, labels

def load_data_buzzfeed(file_name="../data/buzzfeed-facebook/buzzfeed-v02-originalLabels.txt", classes = 2):
    print("Loading data buzzfeed...")
    data_train = pd.read_table(file_name, sep='\t', header=None, names=["ID", "URL", "label", "data", "domain", "source"],
                               usecols=[2, 3])
    print(data_train.shape)
    '''
    texts = []
    labels = []
    for idx in range(data_train.data.shape[0]):
        #text = BeautifulSoup(data_train.data[idx])
        texts.append(clean_str(text.get_text().encode('ascii', 'ignore')))
        labels.append(data_train.label[idx])
    '''

    texts = data_train.data
    labels = data_train.label

    if (classes == 2):
        transdict = {
            'mostly true': 0,
            'mostly false': 1,

            'mixture of true and false': 5,
            'no factual content': 5,
        }
    else:
        transdict = {
            'no factual content': 0,
            'mostly true': 1,
            'mixture of true and false': 2,
            'mostly false': 3
        }
    labels = [transdict[i] for i in labels]
    #labels = to_cat(np.asarray(labels))
    print(texts[0:6])
    print(labels[0:6])
    print(pd.value_counts((labels)))
    return texts, labels

def balance_data(texts, labels, sample_size = None, discard_labels=[]):
    ## sample size is the number of items we want to have from EACH class
    unique, counts = np.unique(labels, return_counts=True)
    print(np.asarray((unique, counts)).T)
    all_index = np.empty([0], dtype=int)
    for l, f in zip(unique, counts):
        if (l in discard_labels):
            print ("Discarding items for label " + str(l))
            continue
        l_index = (np.where(labels == l)[0]).tolist()  ## index of input data with current label
        if (sample_size == None ):
            # print "No up or down sampling")
            l_index = np.asarray(l_index)
        elif (sample_size - f > 0):
            # print "Upsampling ", sample_size - f, " items for class ", l
            x = np.random.choice(f, sample_size - f).tolist()
            l_index = np.append(np.asarray(l_index), np.asarray(l_index)[x])
        else:
            # print "Downsampling ", sample_size , " items for class ", l
            l_index = random.sample(l_index, sample_size)
        all_index = np.append(all_index, l_index)
    bal_labels = np.asarray(labels)[all_index.tolist()]
    bal_texts = np.asarray(texts)[all_index.tolist()]
    remaining = [i for i in range(0, np.sum(counts)) if i not in all_index.tolist()]
    rem_texts = np.asarray(texts)[remaining]
    rem_labels = np.asarray(labels)[remaining]
    print ("Final size of dataset:")
    unique, counts = np.unique(bal_labels, return_counts=True)
    print (np.asarray((unique, counts)).T)
    print ("Final size of remaining dataset:")
    unique, counts = np.unique(rem_labels, return_counts=True)
    print (np.asarray((unique, counts)).T)
    return bal_texts, bal_labels, rem_texts, rem_labels


def load_data_snopes(file_name, classes = 2 ):
    # Useful for reading from the following files:
    # "../data/snopes/snopes_checked_v02_right_forclassificationtest.csv"
    # "../data/snopes/snopes_leftover_v02_right_forclassificationtrain.csv"

    print("Loading data snopes...")
    data_train = pd.read_csv(file_name)
    print(data_train.shape)
    print(data_train.label[0:10])
    print(data_train.label.unique())
    # print(data_train[data_train["label"].isnull()])
    texts = data_train.data
    labels = data_train.label

    if (classes == 2):
        transdict = {
            'ftrue': 0,
            'mtrue': 0,
            'mfalse': 1,
            'ffalse': 1,

            'mixture': 5,
        }
    else:
        transdict = {
            'ftrue': 0,
            'mtrue': 1,
            'mixture': 2,
            'mfalse': 3,
            'ffalse': 4,
        }
    labels = [transdict[i] for i in labels]
    # labels = to_cat(np.asarray(labels))
    print("Data from Snopes looks like...")
    print(texts[0:10])
    print(labels[0:10])
    print(pd.value_counts((labels)))
    return texts, labels



def load_data_snopes312(file_name="../data/snopes/snopes_checked_v02_forCrowd.csv", classes = 2):
    print("Loading data snopes312...")
    df = pd.read_csv(file_name, encoding="ISO-8859-1")

    print(df.shape)
    print(df[0:3])
    df = df[df["assessment"] == "right"]
    print(pd.crosstab(df["assessment"], df["fact_rating_phase1"], margins=True))
    labels = df.fact_rating_phase1
    texts = df.original_article_text_phase2     .apply(lambda x: clean_str(BeautifulSoup(x).encode('ascii', 'ignore')))
    #
    '''
    texts = []
    labels = []
    print(df.original_article_text_phase2.shape[0])
    print(df.original_article_text_phase2[2])

    for idx in range(df.original_article_text_phase2.shape[0]):
        text = BeautifulSoup(df.original_article_text_phase2[idx])
        texts.append(clean_str(text.get_text().encode('ascii', 'ignore')))
        labels.append(df.fact_rating_phase1[idx])
    '''

    if (classes == 2):
        transdict = {
            'true': 0,
            'mostly true': 0,
            'mixture': 5,
            'mostly false': 1,
            'false': 1
        }
    else:
        transdict = {
            'true': 1,
            'mostly true': 2,
            'mixture': 3,
            'mostly false': 4,
            'false': 5
        }


    labels = [transdict[i] for i in labels]
    # labels = to_cat(np.asarray(labels))
    print("Data from SnopesChecked looks like...")
    print(texts[0:10])
    print(labels[0:10])
    print(pd.value_counts((labels)))
    return texts, labels


def load_data_buzzfeedtop(file_name="../data/buzzfeed-top/buzzfeed-top.csv"):
    print("Loading data buzzfeedtop...")
    df = pd.read_csv(file_name, encoding="ISO-8859-1")
    print(df.shape)
    print(df[0:3])
    #texts = df.original_article_text_phase2.apply(lambda x: clean_str(BeautifulSoup(x).encode('ascii', 'ignore')))
    texts = df.original_article_text_phase2
    labels = [1] * len(df.original_article_text_phase2) # all are false news
    #labels = "false" * len(df.original_article_text_phase2)
    print("Data from BuzzFeed looks like...")
    print(texts[0:10])
    print(labels[0:10])
    print(pd.value_counts((labels)))
    return texts, labels




def load_data_emergent(file_name="../data/emergent/url-versions-2015-06-14.csv", classes = 2):
    print("Loading data emergent...")
    df = pd.read_csv(file_name, encoding="ISO-8859-1")

    print(df.shape)
    print(df[0:3])
    df = df.drop_duplicates(
        df.columns.difference(['articleVersionId', 'articleVersion', 'articleUrl']),
        keep="last")
    df = df[df["articleBody"] != ""]
    print(pd.crosstab(df["articleStance"], df["claimTruthiness"], margins=True))

    df = df[df["articleStance"] == "for"]

    labels = df.claimTruthiness
    texts = df.articleBody.apply(lambda x: str(x)) #apply(lambda x: clean_str(BeautifulSoup(str(x)).encode('ascii', 'ignore')))

    if (classes == 2):
        transdict = {
            'true': 0,
            'false': 1,
            'unknown': 5
        }
    else:
        transdict = {
            'true': 1,
            'false': 2,
            'unknown': 0
        }

    labels = [transdict[i] for i in labels]
    # labels = to_cat(np.asarray(labels))
    print("Data from Emergent looks like...")
    print(texts[0:10])
    print(labels[0:10])
    print(pd.value_counts((labels)))
    return texts, labels




def load_data_perez(file_name="../data/perez/celeb.csv"):
    print("Loading data perez...")
    df = pd.read_csv(file_name, encoding="ISO-8859-1")
    print(df.shape)
    print(df[0:3])
    #texts = df.original_article_text_phase2.apply(lambda x: clean_str(BeautifulSoup(x).encode('ascii', 'ignore')))
    texts = df.text
    labels = df.label
    transdict = {
        'legit': 0,
        'fake': 1
    }
    labels = [transdict[i] for i in labels]
    #labels = "false" * len(df.original_article_text_phase2)
    print("Data from perez looks like...")
    print(texts[0:10])
    print(labels[0:10])
    print(pd.value_counts((labels)))
    return texts, labels





#path = untar_data(URLs.IMDB_SAMPLE)
path =  "~/workspace/shared/sfu/fake_news/dump/fastai"

CLASSES = 2

texts_all = np.load("../dump/trainRaw")
labels_all = np.load("../dump/trainlRaw")
texts_train_external = np.load("../dump/trainRaw_external")
texts_valid_external = np.load("../dump/validRaw_external")
texts_test_external = np.load("../dump/testRaw_external")
labels_train_external = np.load("../dump/trainlRaw_external")
labels_valid_external = np.load("../dump/validlRaw_external")
labels_test_external = np.load("../dump/testlRaw_external")

texts_snopesChecked, labels_snopesChecked = load_data_snopes("../data/snopes/snopes_checked_v02_right_forclassificationtest.csv", CLASSES)
texts_buzzfeedTop, labels_buzzfeedTop = load_data_buzzfeedtop()
texts_perez, labels_perez = load_data_perez("../data/perez/celeb.csv")

print("Data loaded from disk!")


# Use training data for language model tuning (or some external big [unlabeled] corpus)
#train_df = pd.DataFrame( {'label':  labels_train_external.astype(str), 'text':  texts_train_external})
#valid_df = pd.DataFrame( { 'label':  labels_valid_external.astype(str), 'text':  texts_valid_external})
print(labels_all.shape, int(labels_all.shape[0]/3))

if(LOAD_LM_FROM_DISK):
    data_lm = TextLMDataBunch.load(path + "/languageModel")
    learn = language_model_learner(data_lm, pretrained_model=URLs.WT103, drop_mult=0.5)
    learn.load_encoder("../../languageModel/models/"+ 'LM_selfData')
else:
    texts_valid, labels_valid, texts_train, labels_train = balance_data(texts_all, labels_all, int(labels_all.shape[0]/3), [2,3,4,5])
    train_df = pd.DataFrame( {'label':  labels_train.astype(str), 'text':  texts_train})
    valid_df = pd.DataFrame( { 'label':  labels_valid.astype(str), 'text':  texts_valid})
    data_lm = TextLMDataBunch.from_df(path + "/languageModel", train_df = train_df, valid_df = valid_df)
    learn = language_model_learner(data_lm, pretrained_model=URLs.WT103, drop_mult=0.5)
    train_df = pd.DataFrame( {'label':  labels_train.astype(str), 'text':  texts_train})
    valid_df = pd.DataFrame( { 'label':  labels_valid.astype(str), 'text':  texts_valid})
    print(train_df.head(3))
    data_lm = TextLMDataBunch.from_df(path + "/languageModel", train_df = train_df, valid_df = valid_df)
    data_lm.save()
    learn = language_model_learner(data_lm, pretrained_model=URLs.WT103, drop_mult=0.5)
    # Building a language model
    print("Language model learning")
    learn.freeze_to(-1)
    learn.fit_one_cycle(1, 1e-3/2)
    learn.unfreeze()
    learn.fit(10, 1e-3)
    learn.save_encoder('LM_selfData')


def predict(model, mytexts):
    return [model.predict(x)[0] for x in mytexts]


# ******************************
# ****Classifier model**********
print("Cross validation starts:")
kf = StratifiedKFold(n_splits=3)
for train, valid in kf.split(texts_all, labels_all):
    print("%s %s" % (train, valid))
    texts_train, texts_valid = texts_all[train], texts_all[valid]
    labels_train, labels_valid = labels_all[train], labels_all[valid]
    print(texts_train.shape)
    print(texts_valid.shape)

    train_df = pd.DataFrame({'label': labels_train.astype(str), 'text': texts_train})
    valid_df = pd.DataFrame({'label': labels_valid.astype(str), 'text': texts_valid})
    print("\n\n A sample of classifier training data:")
    print(train_df.head(100))
    data_clas = TextClasDataBunch.from_df(path + "/classification", train_df=train_df, valid_df=valid_df,
                                          vocab=data_lm.train_ds.vocab, bs=32)
    learn = text_classifier_learner(data_clas, drop_mult=0.7)
    learn.load_encoder("../../languageModel/models/" + 'LM_selfData')
    print("Language model loaded!")
    print("Building the text classifier...")
    learn.freeze()
    learn.freeze_to(-1)
    learn.fit_one_cycle(1, 1e-2)
    learn.freeze_to(-2)
    learn.fit(1, 1e-3)

    learn.unfreeze()
    learn.fit(1, 1e-3)
    # learn.fit_one_cycle(1, 1e-3)
    # learn.fit_one_cycle(1, 1e-3/2.)
    learn.fit(15, slice(2e-3 / 100, 2e-3))
    print("saving the classifier...")
    learn.save('TC_LM_selfData')

    # Predictions
    sentence = "Hilary Clinton won the 2016 US election"
    p = learn.predict(sentence)
    print("Prediction for sentence \" " + sentence + "\" is " + str(p))

    print("Results on all  data:")
    y = predict(learn, texts_all)
    print(classification_report(labels_all, list(map(int, y))))


    print("Results on validation data:")
    y = predict(learn, texts_valid)
    print(classification_report(labels_valid, list(map(int, y))))

    print( "Test results on data sampled only from snopes (snopes312 dataset manually checked right items -- unseen claims):")
    texts_test, labels_test, texts, labels = balance_data(texts_snopesChecked, labels_snopesChecked, None, [2, 5])
    y = predict(learn, texts_test)
    print(classification_report(labels_test, list(map(int, y))))

    print("Test results on data sampled only from buzzfeedTop (mixed claims):")
    texts_test, labels_test, texts, labels = balance_data(texts_buzzfeedTop, labels_buzzfeedTop, sample_size=None,
                                                          discard_labels=[])
    y = predict(learn, texts_test)
    print(classification_report(labels_test, np.asarray(y).astype(int)))

    print("Test results on data sampled only from perez (celebrity stories):")
    texts_test, labels_test, texts, labels = balance_data(texts_perez, labels_perez, sample_size=None,
                                                          discard_labels=[])
    y = predict(learn, texts_test)
    print(classification_report(labels_test,np.asarray(y).astype(int)))

